{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(data,m,c):\n",
    "    total_cost=0\n",
    "    M=len(data)\n",
    "    for i in range(M):\n",
    "        x=data[i,0]\n",
    "        y=data[i,1]\n",
    "        total_cost+=(1/M)* ((y-m*x-c)**2)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(data,learning_rate,m,c):\n",
    "    m_slope=0\n",
    "    c_slope=0\n",
    "    a=len(data)\n",
    "    for i in range(a):\n",
    "        x=data[i,0]\n",
    "        y=data[i,1]\n",
    "        m_slope+=(2/a)*(y-m*x-c)*(-x)\n",
    "        c_slope+=(2/a)*(y-m*x-c)*(-1)\n",
    "    m=m-(learning_rate*m_slope)\n",
    "    c=c-(learning_rate*c_slope)\n",
    "      \n",
    "    return m,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(data,learning_rate,iteration):\n",
    "    m=0\n",
    "    c=0\n",
    "    for j in range(iteration):\n",
    "        m,c = step_gradient(data,learning_rate,m,c)\n",
    "        print(\"loss\",j,loss(data,m,c))\n",
    "    return m,c\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run ():\n",
    "    data =np.loadtxt(\"Desktop\\linerar regression dummy data\\data.csv\",delimiter=\",\")\n",
    "    learning_rate=0.0001\n",
    "    iteration=20\n",
    "    m,c=gd(data,learning_rate, iteration)\n",
    "    print(m,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0 1484.5865574086486\n",
      "loss 1 457.8542575737672\n",
      "loss 2 199.5099857255389\n",
      "loss 3 134.50591058200533\n",
      "loss 4 118.1496934223995\n",
      "loss 5 114.0341490603815\n",
      "loss 6 112.99857731713657\n",
      "loss 7 112.73798187568467\n",
      "loss 8 112.6723843590911\n",
      "loss 9 112.65585181499745\n",
      "loss 10 112.65166489759581\n",
      "loss 11 112.6505843615011\n",
      "loss 12 112.65028544701502\n",
      "loss 13 112.65018320293967\n",
      "loss 14 112.650130445072\n",
      "loss 15 112.65009013922885\n",
      "loss 16 112.6500529669463\n",
      "loss 17 112.65001658353178\n",
      "loss 18 112.64998039901865\n",
      "loss 19 112.64994426496071\n",
      "1.478895662279729 0.030269517287775903\n"
     ]
    }
   ],
   "source": [
    "run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
