{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00828f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Concatenate,Dropout,Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12211e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv('twitter_training.csv')\n",
    "data_test=pd.read_csv('twitter_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "708a36ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0  Positive  I am coming to the borders and I will kill you...\n",
       "1  Positive  im getting on borderlands and i will kill you ...\n",
       "2  Positive  im coming on borderlands and i will murder you...\n",
       "3  Positive  im getting on borderlands 2 and i will murder ...\n",
       "4  Positive  im getting into borderlands and i can murder y..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns=['no1','no2','sentiment','text']\n",
    "data_train.drop('no1',axis=1,inplace=True)\n",
    "data_train.drop('no2',axis=1,inplace=True)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3e5ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Hi @EAHelp I’ve had Madeleine McCann in my cel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "0       Neutral  BBC News - Amazon boss Jeff Bezos rejects clai...\n",
       "1      Negative  @Microsoft Why do I pay for WORD when it funct...\n",
       "2      Negative  CSGO matchmaking is so full of closet hacking,...\n",
       "3       Neutral  Now the President is slapping Americans in the...\n",
       "4      Negative  Hi @EAHelp I’ve had Madeleine McCann in my cel...\n",
       "..          ...                                                ...\n",
       "994  Irrelevant  ⭐️ Toronto is the arts and culture capital of ...\n",
       "995  Irrelevant  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...\n",
       "996    Positive  Today sucked so it’s time to drink wine n play...\n",
       "997    Positive  Bought a fraction of Microsoft today. Small wins.\n",
       "998     Neutral  Johnson & Johnson to stop selling talc baby po...\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.columns=['no1','no2','sentiment','text']\n",
    "data_test.drop('no1',axis=1,inplace=True)\n",
    "data_test.drop('no2',axis=1,inplace=True)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27364f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.dropna(inplace=True)\n",
    "data_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ca584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['sentiment']=data_train['sentiment'].map({'Positive':0,'Negative':2,'Neutral':1,'Irrelevant':3})\n",
    "data_test['sentiment']=data_test['sentiment'].map({'Positive':0,'Negative':2,'Neutral':1,'Irrelevant':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c488c6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(73995, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sentiment=np.array(data_train.iloc[:,0])\n",
    "x_train_sentiment=tf.one_hot(x_train_sentiment, 4)\n",
    "x_train_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25958fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(999, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_sentiment=np.array(data_test.iloc[:,0])\n",
    "x_test_sentiment=tf.one_hot(x_test_sentiment, 4)\n",
    "x_test_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de7120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    '''Removes HTML tags: replaces anything between opening and closing <> with empty space'''\n",
    "\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a43faf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "496aee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    '''Cleans text data up, leaving only 2 or more char long non-stepwords composed of A-Z & a-z only\n",
    "    in lowercase'''\n",
    "    \n",
    "    sentence = sen.lower()\n",
    "\n",
    "    # Remove html tags\n",
    "    sentence = remove_tags(sentence)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)  # When we remove apostrophe from the word \"Mark's\", the apostrophe is replaced by an empty space. Hence, we are left with single character \"s\" that we are removing here.\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)  # Next, we remove all the single characters and replace it by a space which creates multiple spaces in our text. Finally, we remove the multiple spaces from our text as well.\n",
    "\n",
    "    # Remove Stopwords\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "    sentence = pattern.sub('', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59bf3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text = []\n",
    "sentences = list(data_train['text'])\n",
    "for sen in sentences:\n",
    "    x_train_text.append(preprocess_text(sen))\n",
    "    \n",
    "    \n",
    "x_test_text = []\n",
    "sentences = list(data_test['text'])\n",
    "for sen in sentences:\n",
    "    x_test_text.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5d41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train_text\n",
    "y_train=x_train_sentiment\n",
    "x_test=x_test_text\n",
    "y_test=x_test_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ea64f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4259126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 32\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "x_train = bert_tokenizer.batch_encode_plus(\n",
    "    x_train,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    return_token_type_ids=False,\n",
    "    padding='max_length',\n",
    "    max_length=max_length,\n",
    "    return_tensors='tf',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "max_length = 32\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "x_test = bert_tokenizer.batch_encode_plus(\n",
    "    x_test,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    return_token_type_ids=False,\n",
    "    padding='max_length',\n",
    "    max_length=max_length,\n",
    "    return_tensors='tf',\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c35724e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = x_train['input_ids'].numpy()\n",
    "attention_masks = x_train['attention_mask'].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba97b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[input_ids,attention_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0436013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  101,  2746,  6645, ...,     0,     0,     0],\n",
       "        [  101, 10047,  2893, ...,     0,     0,     0],\n",
       "        [  101, 10047,  2746, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  3651,  3645, ...,     0,     0,     0],\n",
       "        [  101,  3651,  3645, ...,     0,     0,     0],\n",
       "        [  101,  2066,  3645, ...,     0,     0,     0]]),\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a6e24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids2 = x_test['input_ids'].numpy()\n",
    "attention_masks2 = x_test['attention_mask'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "078e5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[input_ids2,attention_masks2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70bab8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  101,  4035,  2739, ...,     0,     0,     0],\n",
       "        [  101,  7513,  3477, ...,     0,     0,     0],\n",
       "        [  101, 20116,  3995, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2651,  8631, ...,     0,     0,     0],\n",
       "        [  101,  4149, 12884, ...,     0,     0,     0],\n",
       "        [  101,  3779,  3779, ...,     0,     0,     0]]),\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf4b75a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e6435f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d578c5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the BERT layers\n",
    "bert_model.trainable = True\n",
    "\n",
    "# BERT embeddings\n",
    "input_ids_input = Input(shape=(max_length,), dtype='int32')\n",
    "attention_mask_input = Input(shape=(max_length,), dtype='int32')\n",
    "bert_output = bert_model([input_ids_input, attention_mask_input])[0]\n",
    "\n",
    "# CNN layer\n",
    "num_filters = 32\n",
    "kernel_size = 5\n",
    "cnn_layer = Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu')(bert_output)\n",
    "cnn_layer=Dropout(0.2)(cnn_layer)\n",
    "cnn_layer = MaxPooling1D()(cnn_layer)\n",
    "\n",
    "# CNN layer\n",
    "num_filters = 64\n",
    "kernel_size = 5\n",
    "cnn_layer2 = Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu')(cnn_layer)\n",
    "cnn_layer2=Dropout(0.2)(cnn_layer2)\n",
    "cnn_layer2 = MaxPooling1D()(cnn_layer2)\n",
    "# LSTM layer\n",
    "\n",
    "lstm_layer = Bidirectional(LSTM(32, return_sequences=True))(cnn_layer2)\n",
    "lstm_layer = Bidirectional(LSTM(64, return_sequences=True))(lstm_layer)\n",
    "attention_layer=attention()(lstm_layer)\n",
    "# Output layer\n",
    "output_layer = Dense(4, activation='sigmoid')(attention_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input_ids_input, attention_mask_input], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(lr=2e-5)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5401c7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_2 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_5[0][0]',                \n",
      "                                thPoolingAndCrossAt               'input_6[0][0]']                \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 32,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 28, 32)       122912      ['tf_bert_model_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_113 (Dropout)          (None, 28, 32)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 14, 32)      0           ['dropout_113[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 10, 64)       10304       ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_114 (Dropout)          (None, 10, 64)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 5, 64)       0           ['dropout_114[0][0]']            \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 5, 64)       24832       ['max_pooling1d_3[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 5, 128)      66048       ['bidirectional_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " attention (attention)          (None, 128)          133         ['bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            516         ['attention[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,706,985\n",
      "Trainable params: 109,706,985\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  6/290 [..............................] - ETA: 9:05:31 - loss: 0.6766 - accuracy: 0.2760"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=256, epochs=2,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b284be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array=y_test_pred\n",
    "binary_array = np.zeros_like(input_array)\n",
    "max_indices = np.argmax(input_array, axis=1)\n",
    "binary_array[np.arange(len(input_array)), max_indices] = 1\n",
    "y_test_pred=binary_array\n",
    "print(binary_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cf01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
